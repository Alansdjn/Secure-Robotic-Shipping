{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader,Dataset\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(data):\n",
    "    m = np.mean(data)\n",
    "    mx = max(data)\n",
    "    mn = min(data)\n",
    "    return np.array([[(i - m)/(mx - mn) for i in data]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config_r():\n",
    "    reid_robot_dir = \"./data/reid_robot/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestSiameseNetworkDataset(Dataset):\n",
    "    \n",
    "    def __init__(self,imageFolderDataset,transform=None):\n",
    "        self.imageFolderDataset = imageFolderDataset  \n",
    "        self.transform = transform\n",
    "        \n",
    "    def __getitem__(self,index):\n",
    "        img0_tuple = self.imageFolderDataset.imgs[index]#imgs has the form like [('./person_i/xxx.jpg',label_i),...]\n",
    "        img0 = Image.open(img0_tuple[0])\n",
    "        \n",
    "        #global HSV feature\n",
    "        img0_hsv = img0.convert('HSV')\n",
    "        \n",
    "        #local Laplacian texture feature\n",
    "        img0_grad = cv2.imread(img0_tuple[0])\n",
    "        img0_grad = cv2.Laplacian(img0_grad,cv2.CV_16S,ksize = 3)\n",
    "        img0_grad = cv2.convertScaleAbs(img0_grad)#absolute value\n",
    "        img0_grad = Image.fromarray(img0_grad.astype('uint8')).convert('RGB')\n",
    "        \n",
    "        if self.transform is not None:\n",
    "            img0_hsv = self.transform(img0_hsv)\n",
    "            img0_grad = self.transform(img0_grad)\n",
    "        label = img0_tuple[1]\n",
    "        return img0_hsv, img0_grad, label\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.imageFolderDataset.imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#a simple CNN with 3 convolutional layers and 3 fully connected layers\n",
    "class SiameseNetwork(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(SiameseNetwork, self).__init__()\n",
    "        self.cnn = nn.Sequential(\n",
    "            nn.ReflectionPad2d(1),\n",
    "            nn.Conv2d(3, 12, kernel_size=3),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.BatchNorm2d(12),\n",
    "            \n",
    "            nn.ReflectionPad2d(1),\n",
    "            nn.Conv2d(12, 24, kernel_size=3),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.BatchNorm2d(24),\n",
    "\n",
    "            nn.ReflectionPad2d(1),\n",
    "            nn.Conv2d(24, 24, kernel_size=3),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.BatchNorm2d(24),\n",
    "        )\n",
    "\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(24*160*60, 500),\n",
    "            nn.ReLU(inplace=True),\n",
    "\n",
    "            nn.Linear(500, 500),\n",
    "            nn.ReLU(inplace=True),\n",
    "\n",
    "            nn.Linear(500, 18),\n",
    "        )\n",
    "\n",
    "    def forward(self, input0, input1):\n",
    "        \n",
    "        output0 = self.cnn(input0)#batch_size * depth * width * height\n",
    "        output0 = output0.view(output0.size()[0], -1)#(batch_size) * (depth * width * height)\n",
    "        output0 = self.fc(output0)\n",
    "        \n",
    "        output1 = self.cnn(input1)\n",
    "        output1 = output1.view(output1.size()[0], -1)\n",
    "        output1 = self.fc(output1)\n",
    "        \n",
    "        return output0, output1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f_Distance(img0_hsv, img0_grad, img1_hsv, img1_grad):\n",
    "    a = 0.9\n",
    "    output0_hsv,output1_hsv = net(Variable(img0_hsv),Variable(img1_hsv))\n",
    "    output0_grad,output1_grad = net(Variable(img0_grad),Variable(img1_grad))\n",
    "    output0 = torch.cat((a * output0_hsv, (1-a) * output0_grad), 1)\n",
    "    output1 = torch.cat((a * output1_hsv, (1-a) * output1_grad), 1)\n",
    "                \n",
    "    euclidean_distance = F.pairwise_distance(output0, output1)\n",
    "    cos_distance = np.linalg.norm(normalize(output0.data.numpy()[0]) - normalize(output1.data.numpy()[0]))\n",
    "    distance  = cos_distance * euclidean_distance\n",
    "    return distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "distance:5.948\n",
      "same person\n"
     ]
    }
   ],
   "source": [
    "if __name__=='__main__':\n",
    "    net = SiameseNetwork()\n",
    "    \n",
    "    #load model\n",
    "    save_p = \"./net_test.pth\"\n",
    "    checkpoint = torch.load(save_p)\n",
    "    net.load_state_dict(checkpoint['net'])\n",
    "\n",
    "    #load target person's prepared photo and the captured photo\n",
    "    folder_dataset_test = dset.ImageFolder(root=Config_r.reid_robot_dir)\n",
    "    reid_robot_siamese_dataset = TestSiameseNetworkDataset(imageFolderDataset=folder_dataset_test,\n",
    "                                        transform=transforms.Compose([transforms.Resize((160,60)),\n",
    "                                                                      transforms.ToTensor()]))\n",
    "    reid_robot_dataloader = DataLoader(reid_robot_siamese_dataset,num_workers=0,batch_size=1,shuffle=False)\n",
    "    \n",
    "    _,data1 = list(enumerate(reid_robot_dataloader,0))[0]\n",
    "    _,data2 = list(enumerate(reid_robot_dataloader,0))[1]\n",
    "    img0_hsv, img0_grad,_ = data1\n",
    "    img1_hsv, img1_grad,_ = data2\n",
    "    distance = f_Distance(img0_hsv, img0_grad, img1_hsv, img1_grad)\n",
    "    distance = distance.detach().numpy().tolist()[0]\n",
    "    print(\"distance:{:.3f}\".format(distance))\n",
    "    \n",
    "    limit_dis = 10\n",
    "    max_dis = 8.840#gain before robot delivering\n",
    "    judge_dis = min(limit_dis, max_dis)\n",
    "    \n",
    "    if distance < judge_dis:\n",
    "        print('same person')\n",
    "    else:\n",
    "        print('different person')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
